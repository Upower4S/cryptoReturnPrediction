{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b406836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import talib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1410ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df = pd.read_csv('BTCUSDC-1m-2years.csv') \n",
    "btc_df['timestamp'] = pd.to_datetime(btc_df['timestamp'],dayfirst=True )\n",
    "btc_df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8024d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "class RandomizedSignatureDrift:\n",
    "    def __init__(self, rd=50, rm=0.05, rv=0.03, alpha=1e-3, tw=120):\n",
    "        \"\"\"\n",
    "        Initialize parameters based on Table 1 and Section 2.2.\n",
    "        \n",
    "        Args:\n",
    "            rd (int): Reservoir dimension (r_d) [cite: 831]\n",
    "            rm (float): Mean of random projection entries (r_m) [cite: 188]\n",
    "            rv (float): Variance of random projection entries (r_v) [cite: 188]\n",
    "            alpha (float): Regularization for Ridge regression [cite: 225]\n",
    "            tw (int): Rolling window size / start index (t_w) [cite: 200]\n",
    "        \"\"\"\n",
    "        self.rd = rd\n",
    "        self.rm = rm\n",
    "        self.rv = rv\n",
    "        self.alpha = alpha\n",
    "        self.tw = tw\n",
    "        self.activation = np.tanh # Common choice for sigma in Reservoir Computing\n",
    "\n",
    "    def _generate_reservoir_system(self, input_dim):\n",
    "        \"\"\"\n",
    "        Generates the random matrices A_i and biases b_i for Eq (4)[cite: 183].\n",
    "        \n",
    "        Input dimension is d+1 (stocks + time).\n",
    "        There is one matrix A and bias b for each input dimension component.\n",
    "        \"\"\"\n",
    "        # A_i: Shape (input_dim, rd, rd)\n",
    "        # Entries follow N(rm, rv) [cite: 188]\n",
    "        # We use standard deviation = sqrt(rv) for numpy's normal function\n",
    "        self.A = np.random.normal(loc=self.rm, scale=np.sqrt(self.rv), \n",
    "                                  size=(input_dim, self.rd, self.rd))\n",
    "        \n",
    "        # b_i: Shape (input_dim, rd)\n",
    "        # Entries follow N(0, 1) [cite: 188]\n",
    "        self.b = np.random.normal(loc=0, scale=1, \n",
    "                                  size=(input_dim, self.rd))\n",
    "\n",
    "    def compute_signatures(self, X_augmented):\n",
    "        \"\"\"\n",
    "        Computes the randomized signature (Reservoir state Y) via Euler scheme.\n",
    "        Eq (4): dR_t = sum(sigma(A_i R_t + b_i) dX^i_t) [cite: 183]\n",
    "        \"\"\"\n",
    "        T, input_dim = X_augmented.shape\n",
    "        \n",
    "        # Initialize R_0 ~ N(0, I) [cite: 184]\n",
    "        R = np.zeros((T, self.rd))\n",
    "        R[0] = np.random.normal(0, 1, self.rd)\n",
    "        \n",
    "        # Calculate increments dX (simple difference for discrete time)\n",
    "        # Note: dX[t] drives the change from R[t] to R[t+1]\n",
    "        dX = np.diff(X_augmented, axis=0, prepend=0) \n",
    "\n",
    "        # Euler Discretization Loop\n",
    "        for t in range(T - 1):\n",
    "            update_sum = np.zeros(self.rd)\n",
    "            \n",
    "            # Summation over input dimensions i=0 to d\n",
    "            for i in range(input_dim):\n",
    "                # Linear projection: A_i * R_t + b_i\n",
    "                proj = np.dot(self.A[i], R[t]) + self.b[i]\n",
    "                # Activation and multiplication by increment dX^i\n",
    "                update_sum += self.activation(proj) * dX[t, i]\n",
    "            \n",
    "            R[t+1] = R[t] + update_sum\n",
    "            \n",
    "        return R\n",
    "\n",
    "    def predict(self, prices):\n",
    "        \"\"\"\n",
    "        Main algorithm from Appendix 3[cite: 889].\n",
    "        \"\"\"\n",
    "        # 1. Preprocessing: Log returns (Leading increments) [cite: 172]\n",
    "        # Normalizing by initial value is mentioned in [cite: 172]\n",
    "        prices = np.array(prices)\n",
    "        log_prices = np.log(prices / prices[0]) \n",
    "        X_log_returns = np.diff(log_prices, axis=0) # Length T-1\n",
    "        y_returns = np.where(X_log_returns>0, 1,-1)\n",
    "        \n",
    "        # 2. Data Augmentation: Add time as 0-th dimension [cite: 195]\n",
    "        T_len, _ = X_log_returns.shape\n",
    "        time_index = np.arange(T_len).reshape(-1, 1) #* (1.0/T_len) # Normalized time\n",
    "        X_augmented = np.hstack([time_index, X_log_returns])\n",
    "        \n",
    "        # 3. Initialize Reservoir System (Random Matrices)\n",
    "        self._generate_reservoir_system(input_dim=X_augmented.shape[1])\n",
    "        \n",
    "        # 4. Compute Reservoir States (Y) [cite: 889]\n",
    "        Y = self.compute_signatures(X_augmented)\n",
    "        \n",
    "        # 5. Set Split Time (t_s) [cite: 229, 889]\n",
    "        # Usually 10% of data, ensuring t_s >> t_w\n",
    "        t_s = int(T_len * 9 / 10)\n",
    "        if t_s <= self.tw:\n",
    "            t_s = self.tw + 10\n",
    "            \n",
    "        predictions = []\n",
    "        \n",
    "        # 6. Main Loop: Train and Predict [cite: 889]\n",
    "        # We iterate to predict the NEXT return. \n",
    "        print(f\"Starting training loop from t={t_s} to {T_len-1}...\")\n",
    "        # Define expanding window training sets\n",
    "        # Inputs: Reservoir states from t_w to t-1\n",
    "\n",
    "        X_train = Y[self.tw : t_s-120]\n",
    "        \n",
    "        # Targets: Log returns from t_w+1 to t (Predicting 1 step ahead)\n",
    "        # We want to map Y[k] -> Return[k+1]\n",
    "        y_train = y_returns[self.tw + 1 : t_s-120 + 1]\n",
    "        \n",
    "        # Ridge classifier Readout [cite: 225]\n",
    "        ridge = RidgeClassifier(alpha=self.alpha, fit_intercept=True)\n",
    "        ridge.fit(X_train, y_train)\n",
    "        for t in range(t_s, T_len-1):\n",
    "            \n",
    "            \n",
    "            # Predict next step: \\hat{X}_{t+1} = M_t(Y_t) [cite: 889]\n",
    "            # We use the current reservoir state Y[t] to predict return at t+1\n",
    "            current_reservoir = Y[t].reshape(1, -1)\n",
    "            pred = ridge.predict(current_reservoir)\n",
    "            predictions.append(pred.flatten())\n",
    "            \n",
    "        y_true = y_returns[t_s+1 : T_len]\n",
    "        ascore = accuracy_score(y_true, predictions)\n",
    "        return ascore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20ade8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop from t=828143 to 920158...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mlkaggle/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5180946791862285\n"
     ]
    }
   ],
   "source": [
    "prices = btc_df.close.values\n",
    "model = RandomizedSignatureDrift(rd=50, rm=0.05, rv=0.03, tw=120)\n",
    "predicted_returns = model.predict(prices[:,np.newaxis])\n",
    "print(predicted_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42a5e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlkaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
